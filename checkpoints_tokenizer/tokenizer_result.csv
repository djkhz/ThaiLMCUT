-;LM;Tokenizer_2019-11-04_00.05.22;domain_novel-news;boundary;89.81;96.47;93.02;word;84.03;90.26;87.03;17;0:34:00.755990;trainLosses  [0.14683846628115554, 0.06392077752506015, 0.05002499546799528, 0.04196589076236339, 0.036528100130901714, 0.03254837543942296, 0.029369441113767013, 0.02664259607299938, 0.02441905695832704, 0.022785579671044297, 0.021185839277266257, 0.019802371084446733, 0.018479468176918264, 0.0176203355518399, 0.01677319535929429, 0.01618818133418921, 0.015400563693142043];devLosses  [0.07270346380684567, 0.054033552606900535, 0.04523480961891426, 0.04010084900876571, 0.03670575099344226, 0.03417365458504907, 0.03244437709793277, 0.031206241070196546, 0.030313767878146006, 0.02959675481007702, 0.028929131169771326, 0.02858537086553272, 0.028124613516118335, 0.027802891750959145, 0.027579783065908258, 0.02734757451361966, 0.027433330300210536];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_00.05.22 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.32.06' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_00.05.22' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_00.45.34;domain_novel-news;boundary;90.22;96.24;93.13;word;84.62;90.26;87.35;20;0:40:11.890598;trainLosses  [0.15105754685536701, 0.06473222895333515, 0.05064633738567781, 0.04250030195218834, 0.03687845611355113, 0.03281436339675931, 0.029549613066167386, 0.026765557541862953, 0.024659716542903803, 0.02285440019261672, 0.021333640409708397, 0.01982757612482537, 0.01877894833796288, 0.017803184250510067, 0.016842186331617923, 0.016253042218495328, 0.015520063717966553, 0.014825369254217936, 0.01425281602739539, 0.013772896969522438];devLosses  [0.07369365333311859, 0.05479425568690245, 0.04588260685746697, 0.04056148068315681, 0.037070053297726585, 0.0346966003249774, 0.03287218718778813, 0.03155856909251761, 0.030656017234613156, 0.029919125803414433, 0.029256408777216386, 0.02892830770933765, 0.02850798909263364, 0.028250289267335815, 0.02815501982795781, 0.02787085170804084, 0.027616064503103836, 0.027509665780368894, 0.02739245007778036, 0.027326620687013387];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_00.45.34 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.32.06' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_00.45.34' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_01.31.56;domain_novel-news;boundary;89.86;96.57;93.09;word;84.05;90.33;87.08;18;0:36:04.909780;trainLosses  [0.1526808672439513, 0.06551160348401447, 0.05124853481655594, 0.042963391361786195, 0.03732772639498639, 0.03322279119124664, 0.029802464482248128, 0.02716556245732547, 0.02494989432179224, 0.02304605073084933, 0.021450666655744216, 0.020078643018042845, 0.018795082663845775, 0.01786029895173208, 0.01696778458529082, 0.016115024453614037, 0.015463654683135337, 0.014928318104992186];devLosses  [0.07453904763377946, 0.05550667754877573, 0.04639704945101135, 0.04112288004708016, 0.037494527047564244, 0.035046013179181636, 0.03325654583415766, 0.031975459264612746, 0.030889705829750532, 0.030188441533466864, 0.029691598110500424, 0.029078832495657878, 0.02873535263726766, 0.028314721567192298, 0.028093051764814334, 0.0279117149097481, 0.027846509612154687, 0.027850172814281506];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_01.31.56 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.32.06' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_01.31.56' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_02.14.03;domain_novel-news;boundary;89.88;96.48;93.06;word;84.11;90.29;87.09;18;0:36:07.084872;trainLosses  [0.15616183883356088, 0.06487770886371035, 0.05053150164309758, 0.042438353105312465, 0.03688034268760651, 0.03290674352232161, 0.02969460756326066, 0.0270326966045415, 0.024880828698582234, 0.023076830124108112, 0.021551364967271912, 0.020172744878244834, 0.01890041194996567, 0.0179228470625646, 0.01707390974739089, 0.016284399192625816, 0.015816464490168283, 0.015015361449171101];devLosses  [0.07414698172574756, 0.054783174147208534, 0.0458941618087648, 0.0406828571924533, 0.03716573254044714, 0.03484197950054859, 0.03302023401376845, 0.031647249092829635, 0.030747250664508206, 0.029966846472401727, 0.029394650660540866, 0.02904665652105863, 0.028701059755751455, 0.028367890451831378, 0.02814080703190003, 0.027996381894610393, 0.027722328858471465, 0.02778749846607104];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_02.14.03 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.32.06' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_02.14.03' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_02.56.17;domain_novel-news;boundary;90.08;96.4;93.13;word;84.46;90.39;87.33;20;0:40:01.523201;trainLosses  [0.1501090559996103, 0.06458923815464104, 0.050498767058603726, 0.04234893152246898, 0.03685622243210673, 0.03288598824526422, 0.029599531415625283, 0.02681329126830152, 0.024514967313588563, 0.022845892805428286, 0.021281862689940326, 0.019963115942781443, 0.01881056612277937, 0.017763754757748326, 0.016946708127720533, 0.016140332323821945, 0.015464424937799686, 0.014821026432117326, 0.01415916218015192, 0.013986533784410499];devLosses  [0.07342048451818269, 0.05464399554606142, 0.04587954723800736, 0.04054730556819631, 0.03708171097283391, 0.03471301618064272, 0.03289784696595422, 0.0315035720109597, 0.030545102667877043, 0.029758368458213478, 0.029186399460866534, 0.028632376878254717, 0.028229584275134677, 0.027968565430278064, 0.027804148051588016, 0.027703081032839316, 0.027429791724031, 0.027336766365273244, 0.02730067885727033, 0.02708171338014219];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_02.56.17 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.32.06' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_02.56.17' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_03.42.23;domain_novel-news;boundary;91.49;95.45;93.43;word;86.53;90.28;88.37;11;0:22:05.382023;trainLosses  [0.13190327593635523, 0.05567823615786269, 0.04546054012268482, 0.03900303337816617, 0.03427948309904217, 0.030675840931453147, 0.02756064914836169, 0.024927402885125287, 0.022826209684234842, 0.020752900609999295, 0.019061431549629897];devLosses  [0.06082546629611103, 0.048188482807285486, 0.041208297956263885, 0.039528957064980746, 0.03299936221848274, 0.030536113242650854, 0.029603542117723102, 0.02803629615354812, 0.027341894270188506, 0.02704329276992672, 0.02732790098793205];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_03.42.23 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_03.42.23' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_04.10.31;domain_novel-news;boundary;91.66;94.76;93.19;word;86.86;89.8;88.31;11;0:22:05.220825;trainLosses  [0.13002177832376718, 0.055067780722475534, 0.04523569559818836, 0.039020483169105634, 0.03449160335398274, 0.030865840384521375, 0.027765723544374184, 0.025167957976713177, 0.0229253503973666, 0.021085128454893978, 0.01929858968190699];devLosses  [0.060543669494746745, 0.047713444536102226, 0.04097748278030034, 0.03923490714153339, 0.03343776637024578, 0.0319171195271714, 0.029845035838327188, 0.028353322425792957, 0.02828415915712543, 0.027583975580403174, 0.02886369486135998];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_04.10.31 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_04.10.31' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_04.38.40;domain_novel-news;boundary;91.49;95.38;93.39;word;86.6;90.28;88.41;12;0:24:08.775803;trainLosses  [0.12959822436710397, 0.055540372888983496, 0.0453482111915946, 0.03897957410429366, 0.03448409649857025, 0.030936189505959576, 0.027813003990499668, 0.02532568992110877, 0.023030585793066938, 0.02116623824583975, 0.019472656414689656, 0.017884082026924732];devLosses  [0.059725645715477824, 0.04769647866487503, 0.04132649897672664, 0.03924452318627944, 0.03393401734359648, 0.03094670872321759, 0.0294533073688033, 0.02889856180154729, 0.027562815139348478, 0.027298704239315, 0.027250664479944897, 0.027874027796346564];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_04.38.40 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_04.38.40' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_05.08.59;domain_novel-news;boundary;92.33;94.59;93.44;word;87.87;90.03;88.94;10;0:20:07.580830;trainLosses  [0.12827737800702077, 0.055433793438027554, 0.04540318582001044, 0.03925606562760682, 0.0346562285701646, 0.031082347938650518, 0.02794003762988065, 0.025368625958024256, 0.023064993699806646, 0.021144064802011878];devLosses  [0.05962631752950021, 0.04771564588293262, 0.04142647913132591, 0.039220825501385774, 0.03317524839578004, 0.031847494558013716, 0.029834803750460177, 0.02776545157720303, 0.02754369035534475, 0.028827129702629715];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_05.08.59 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_05.08.59' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_05.35.12;domain_novel-news;boundary;91.78;95.23;93.47;word;87.06;90.33;88.66;10;0:20:02.919743;trainLosses  [0.1312371868424904, 0.05528660638529302, 0.04521339412441655, 0.03905628083610729, 0.034423502723700435, 0.030851636765215865, 0.027653958573563016, 0.025123481744029865, 0.02297187609780561, 0.020927788924903202];devLosses  [0.05987048174800544, 0.04832180640820799, 0.04092654716437576, 0.037462909331266905, 0.03416546235053704, 0.03127823311878347, 0.029607457397826786, 0.029044663662026668, 0.02751907631326681, 0.027961699998584288];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_05.35.12 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_05.35.12' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_06.01.25;domain_novel-article;boundary;94.02;97.49;95.73;word;89.71;93.02;91.34;19;0:38:05.340623;trainLosses  [0.16487509253710958, 0.07188358189697241, 0.05678551081549282, 0.04827614969587955, 0.04249729023750254, 0.03823686699762042, 0.03486464666343065, 0.03199865194926759, 0.029712627871177306, 0.027732519903243637, 0.025999126941826774, 0.02433562050713928, 0.023182408169295694, 0.022105422280448015, 0.020994427430223506, 0.020105769889354332, 0.01922763441104311, 0.01840462799338465, 0.0179195620959634];devLosses  [0.0816834108240303, 0.06110999416345837, 0.0515665783621799, 0.04578947412899171, 0.04193727040513494, 0.03909677729524415, 0.03707157576392437, 0.035389152708752404, 0.034186283768764855, 0.03315414152183067, 0.0324683180614107, 0.03178979606292714, 0.0311737847782072, 0.03079840568718554, 0.03046135627932247, 0.03009424144509195, 0.02992322347287474, 0.029513152722997225, 0.02953653031125151];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_06.01.25 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.23.51' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_06.01.25' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_06.43.36;domain_novel-article;boundary;93.94;97.63;95.75;word;89.54;93.05;91.26;20;0:40:04.259583;trainLosses  [0.1682941346293568, 0.07217857700271822, 0.057026600072057405, 0.048518746946212936, 0.04277168379057592, 0.038526967715415826, 0.03512531748958793, 0.03230367946536772, 0.02991412148750083, 0.027921881540748643, 0.02635867874039777, 0.024724471745497766, 0.023337562219824772, 0.02223130005140363, 0.0211520941188587, 0.020314177640961793, 0.0194263600009545, 0.018794096963030835, 0.0180133683162381, 0.017446217082684214];devLosses  [0.08166684801208562, 0.06103916089425142, 0.05146111124034586, 0.04572013384480586, 0.04186426064577596, 0.03909541762851436, 0.03703380926330199, 0.03541939457257589, 0.03414170135711801, 0.033144813330694176, 0.03237016950787484, 0.03163500588344431, 0.03108563511792956, 0.030605475557432777, 0.03035415751838136, 0.030002101206745225, 0.029543456182568924, 0.029378743563917863, 0.02914061384468243, 0.028984643411876142];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_06.43.36 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.23.51' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_06.43.36' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_07.27.42;domain_novel-article;boundary;94.06;97.53;95.76;word;89.71;93.02;91.33;20;0:39:55.755566;trainLosses  [0.16095752444998104, 0.07198077937747216, 0.05714680129503036, 0.04852969617344177, 0.0426682970725262, 0.03845298642423659, 0.03505420808834796, 0.03212494927987307, 0.029854966135667498, 0.027899326948477094, 0.026184050113561765, 0.024610103758510634, 0.023223405599771957, 0.022230706040761505, 0.021214757618920214, 0.02008999704884075, 0.019331569908579916, 0.018441559680171273, 0.017855057891823314, 0.017315429992196922];devLosses  [0.0816547919450135, 0.061168173606368316, 0.051639295729069876, 0.04596885023959752, 0.042030235217220484, 0.0392904966084779, 0.03723557062190155, 0.0356415075774508, 0.03446070650785134, 0.03339889746202135, 0.03259915563053098, 0.031899264831652584, 0.0312132825539715, 0.03082328604470039, 0.030496233260665816, 0.030208062530420292, 0.029895497357537007, 0.029539816081523895, 0.02948409297514236, 0.029327935978085144];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_07.27.42 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.23.51' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_07.27.42' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_08.11.39;domain_novel-article;boundary;94.09;97.44;95.74;word;89.79;92.99;91.36;20;0:40:07.385915;trainLosses  [0.16583416609084187, 0.07282358043869237, 0.057807781335771385, 0.04932434434286464, 0.043464853000083015, 0.03909842373953018, 0.03571647620202983, 0.03286429734938034, 0.03040115610607455, 0.028545101339362524, 0.0267890904767991, 0.02518869132322994, 0.023896921389787714, 0.022750225744149342, 0.021793133814365196, 0.02066837155012105, 0.01999630384502848, 0.019168525060226944, 0.01834360600435105, 0.017801051233993403];devLosses  [0.0823719653076139, 0.06197323877064661, 0.05230721668607887, 0.04657105925953251, 0.042503476314161015, 0.039795710994251846, 0.03751429170370102, 0.03591753570255877, 0.03461590623376013, 0.0334961964138623, 0.03275942038102397, 0.03202301617069491, 0.031408554735197415, 0.031029435110160673, 0.030620975291420674, 0.030171858853307264, 0.029888241883667035, 0.029850241717422146, 0.02953137731415102, 0.029635684264973663];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_08.11.39 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.23.51' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_08.11.39' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-04_08.55.49;domain_novel-article;boundary;93.92;97.63;95.74;word;89.5;93.03;91.23;20;0:40:07.068247;trainLosses  [0.15926026163538495, 0.07112526072741453, 0.05621362004391662, 0.04785320932167259, 0.04203284366393284, 0.03793848970970466, 0.034574659714409754, 0.03159971222580977, 0.029407799176066816, 0.02748350765270616, 0.025703607021770134, 0.024270647135212195, 0.022952738702390812, 0.021802940620015837, 0.020804951924493713, 0.01991064445555547, 0.019146992801571613, 0.01835210132997614, 0.017696631658148377, 0.01710294482611756];devLosses  [0.08038436124722163, 0.06023451754416542, 0.050978139727965166, 0.045380631740065826, 0.041510986057163655, 0.038825193505691385, 0.03678072342413596, 0.03515531193336536, 0.03392973456574583, 0.0329966657720078, 0.032178541880914534, 0.03154544956211386, 0.03104514996895845, 0.030624747254896438, 0.030261602937832647, 0.030104367426414598, 0.0297687827641594, 0.029448876799694424, 0.029172501237741833, 0.02897686140890094];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_08.55.49 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_23.23.51' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_08.55.49' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_09.39.57;domain_novel-article;boundary;95.38;97.24;96.3;word;91.96;93.76;92.85;11;0:22:03.752985;trainLosses  [0.12975822334369672, 0.05556517988256174, 0.045574619692174634, 0.039482178648550005, 0.034736504780605956, 0.0312019811063331, 0.02794381546970438, 0.025317088114659315, 0.023191193277811883, 0.021072065526731874, 0.019303310656657996];devLosses  [0.06168648943133738, 0.048755257208456936, 0.04179513640701771, 0.039888491896891046, 0.033765967913914, 0.030850306859818, 0.0301221524761326, 0.028860416712945904, 0.027838880024936008, 0.02716889628476795, 0.027738776079368317];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_09.39.57 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_09.39.57' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_10.06.04;domain_novel-article;boundary;95.83;96.87;96.35;word;92.75;93.76;93.25;10;0:20:01.629579;trainLosses  [0.13017575576171353, 0.05534558537785881, 0.045457968537475746, 0.03900128438947114, 0.03439206189836314, 0.03070327849478353, 0.0275535328564089, 0.024909748052288988, 0.022687717781977812, 0.020772603711337975];devLosses  [0.05975845665938553, 0.04774275738960025, 0.04143284366134255, 0.03841704314296273, 0.03288127922977524, 0.030807566325897456, 0.029808946510498553, 0.02816008328963285, 0.027421021106085557, 0.027994274932505756];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_10.06.04 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_10.06.04' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_10.30.11;domain_novel-article;boundary;95.56;97.01;96.28;word;92.26;93.65;92.95;10;0:20:04.036648;trainLosses  [0.1309533205267098, 0.055548120524041615, 0.04540891837721794, 0.039197078175917645, 0.034648656093950694, 0.031012466865306225, 0.02784106175382458, 0.025261119674966113, 0.02303136280976498, 0.021012534821480886];devLosses  [0.060419131883944585, 0.048726491501619076, 0.04189673524307108, 0.039685215908049166, 0.03384574843120986, 0.03088897021337487, 0.030255014890398103, 0.028994199509421986, 0.02755985445417892, 0.02763878207268386];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_10.30.11 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_10.30.11' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_10.54.19;domain_novel-article;boundary;95.3;97.15;96.22;word;91.84;93.62;92.72;10;0:20:03.891988;trainLosses  [0.13071019659240043, 0.05525169905331267, 0.045433906197136074, 0.03924932000437873, 0.03464140849487491, 0.031007527844072437, 0.02795117137597958, 0.02539405904373332, 0.02316442384599853, 0.021243973639817094];devLosses  [0.05925272533605839, 0.04786773741073992, 0.040907100528136064, 0.039753026403914926, 0.03378718359203174, 0.031376534559089564, 0.030834331466206188, 0.029252013833872204, 0.027667392344995476, 0.027777332983825398];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_10.54.19 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_10.54.19' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-04_23.50.57;BEST_5;boundary;95.95;94.66;95.3;word;93.02;91.77;92.39;13;0:06:15.772193;trainLosses  [0.4267320761841441, 0.12785883306983917, 0.1003708601116188, 0.08783270714301912, 0.08014392314685716, 0.07433534295312942, 0.06903225000179003, 0.06498605199158192, 0.06043831900589996, 0.05709120078337571, 0.05380855630787592, 0.05078164975912798, 0.047753834032586644];devLosses  [0.15784084801533207, 0.11206416392363376, 0.09166085097637976, 0.083982749801615, 0.07723515749162768, 0.07444560024540246, 0.06905394315904712, 0.06760371424350309, 0.06493113420163252, 0.06274207371362248, 0.06111785921019427, 0.06042266561886909, 0.06249942665237077];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-04_23.50.57 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' 5%BEST ,without LM --til converge --lr 0.0001' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'BEST_5' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-04_23.50.57' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-05_00.07.01;BEST_5;boundary;92.44;97.45;94.88;word;86.65;91.34;88.93;8;0:08:04.401363;trainLosses  [0.4230049471296961, 0.12805384001325046, 0.10063390741272578, 0.08788766824300327, 0.08039215467278919, 0.07446047187679344, 0.06925604956608916, 0.06482514396073326];devLosses  [0.15591590485957837, 0.1121341958179237, 0.09197718823640984, 0.08462370131511866, 0.07682687925718586, 0.07394760066169019, 0.06896368240625221, 0.06941484061781295];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_00.07.01 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' 5%BEST ,without LM --til converge --lr 0.0001' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'BEST_5' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_00.07.01' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-05_00.04.27;domain_novel-news;boundary;89.83;96.3;92.95;word;84.07;90.12;86.99;20;0:47:14.899915;trainLosses  [0.14592434452781125, 0.06552695684677842, 0.0512242445619262, 0.04295276153842034, 0.03735219210798117, 0.03315653437608151, 0.029778616545001167, 0.027037948072799037, 0.02502053575332852, 0.023109799834791965, 0.021584515086604496, 0.020091315656526006, 0.018982210579145717, 0.017981727341957503, 0.017134406093751366, 0.016236089963241288, 0.01572512095822162, 0.015041242711639135, 0.014445683187056314, 0.013956322370976883];devLosses  [0.07471053983116972, 0.055620385098388826, 0.046644185123772455, 0.041152072278247485, 0.03763123668045148, 0.03526209823615935, 0.03346083133385099, 0.032238445426712094, 0.03115979374397075, 0.03031280217157013, 0.02968394026245879, 0.029221856495601006, 0.02884331617461539, 0.028577738966064893, 0.028337709348777246, 0.028223361327559097, 0.02806535960528357, 0.027891442500825585, 0.02786979603784523, 0.027767659668093442];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_00.04.27 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news  --LM with out test set' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_10.55.04' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_00.04.27' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-05_01.05.12;domain_novel-news;boundary;91.38;96.02;93.64;word;86.27;90.65;88.4;10;0:20:03.913200;trainLosses  [0.130571797143799, 0.05495192907076685, 0.045189020034375055, 0.03880541656989998, 0.034046941977368676, 0.030480674095919834, 0.027369180855682896, 0.024804728225004583, 0.02256704861855125, 0.02066021541194363];devLosses  [0.05988005398847591, 0.04819744268710586, 0.04106857713269091, 0.03788539148524575, 0.03307671067786628, 0.030801794309725707, 0.0289859466640086, 0.028323073453944306, 0.026672989665263002, 0.026859994635157203];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_01.05.12 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_01.05.12' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-05_01.31.21;domain_novel-article;boundary;93.94;97.15;95.52;word;89.54;92.59;91.04;20;0:40:04.102040;trainLosses  [0.15974553131577957, 0.0743157822947631, 0.05968657987257793, 0.05112590675415406, 0.04526050741217993, 0.04083330259803477, 0.03735411016214358, 0.034393836042127715, 0.03201196229450367, 0.029874863273852584, 0.028154065668695237, 0.026615557726472616, 0.025182937087032512, 0.023901737220210946, 0.022975204527686963, 0.021945225735939104, 0.021147870373252275, 0.020213029646880962, 0.01955966550585388, 0.018843865037273297];devLosses  [0.08370241616991744, 0.06390906095333483, 0.05434683885896343, 0.0483542969343306, 0.0442041314538868, 0.04110763690851886, 0.03896063337123942, 0.03714941334964215, 0.03568996208580746, 0.0344988136798486, 0.033751834654945065, 0.03290714115846431, 0.03231997015061735, 0.03169575444925791, 0.03109018346187712, 0.030822641355381614, 0.03056282231091768, 0.03026377174189721, 0.02993616284053216, 0.029943059980012905];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_01.31.21 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-article  --LM with out test set ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-03_04.35.40' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_01.31.21' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-05_02.37.25;domain_novel-news;boundary;91.5;97.81;94.55;word;86.55;92.52;89.44;6;0:09:58.227470;trainLosses  [0.06259465986516458, 0.027158839026718732, 0.021092879907672654, 0.017352162070581736, 0.014777732523972515, 0.0127138436675989];devLosses  [0.030938452238152767, 0.024553956228426134, 0.022602603149910767, 0.021697963609349454, 0.021081746866305668, 0.0219734030315417];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_02.37.25 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-15_23.45.27' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 1 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_02.37.25' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-05_02.53.28;domain_novel-news;boundary;91.5;97.71;94.51;word;86.57;92.44;89.41;6;0:09:58.663791;trainLosses  [0.060208871761739405, 0.0272085836611164, 0.02109623849672738, 0.01726997318916285, 0.014629148812636958, 0.012632824884184716];devLosses  [0.031179323663999295, 0.024728173828930004, 0.022833866966438705, 0.02169223551520671, 0.021544282870559858, 0.021952238779557848];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_02.53.28 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-15_23.45.27' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 1 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_02.53.28' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-05_03.09.32;domain_novel-news;boundary;91.79;97.54;94.58;word;86.96;92.41;89.6;6;0:09:56.077608;trainLosses  [0.06279754617845817, 0.027465051143013654, 0.021166307524071268, 0.01742382337989744, 0.014755393490171874, 0.012695940021874767];devLosses  [0.031239986462497163, 0.0247662000936167, 0.022746816256094253, 0.021732403008245874, 0.020940514623947526, 0.021596051013932145];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_03.09.32 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_novel-news ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-15_23.45.27' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 1 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_03.09.32' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-05_17.05.15;domain_news-novel;boundary;95.89;94.72;95.3;word;92.71;91.57;92.14;20;1:38:14.213856;trainLosses  [0.18001784948663338, 0.08147821924623165, 0.06256418519096668, 0.052435338671979956, 0.045844420220432336, 0.041140060341141746, 0.0373753483173068, 0.03430069697469306, 0.03178484144324031, 0.02985617690329445, 0.028137439562205494, 0.02649969701660412, 0.025020984112800168, 0.02394245783043973, 0.02300358308614466, 0.02194964820050827, 0.021028823303527008, 0.02051731423480051, 0.01954973399347766, 0.019161386709847596];devLosses  [0.09357611708343029, 0.06692951694130897, 0.05497575122863054, 0.04802572954446077, 0.043551158029586076, 0.04058059357106686, 0.038169188890606165, 0.03640419941395521, 0.035052238069474696, 0.03384952675551176, 0.032896618694067, 0.032072577457875014, 0.03153927752748132, 0.031096484083682298, 0.030447442010045053, 0.029944993257522583, 0.02966641778126359, 0.029389585684984922, 0.029162536654621363, 0.028911828817799686];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_17.05.15 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_news-novel ' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-novel' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-29_07.19.23' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_17.05.15' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-05_22.03.48;domain_news-novel;boundary;96.36;89.9;93.02;word;93.66;87.38;90.41;4;0:19:36.342344;trainLosses  [0.13854331372087228, 0.05519257440913323, 0.04269092529804014, 0.035322852840636694];devLosses  [0.0624178758636117, 0.04811547804623842, 0.042255447898060086, 0.04330243106931448];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-05_22.03.48 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note ' domain_news-novel --without LM' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-novel' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-05_22.03.48' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_11.21.03;domain_news-novel;boundary;96.0;95.08;95.54;word;92.87;91.98;92.43;20;0:37:26.292256;trainLosses  [0.16044034388478243, 0.07436233418863579, 0.05710924523336262, 0.04757493752674018, 0.041427818956321846, 0.037023774986077285, 0.033509398874041085, 0.03065643462472122, 0.028467514530323736, 0.02646958987389863, 0.024977137803948127, 0.023366177026910823, 0.0220554313367472, 0.02109463657226476, 0.01998258657524539, 0.019262104602166395, 0.018391239061410533, 0.01800514217986408, 0.01718579841538348, 0.016767854361623192];devLosses  [0.08434969685971737, 0.06051505822688341, 0.04977301344275475, 0.04367418905720115, 0.03970809208229184, 0.03696503078565001, 0.03503080617636442, 0.03345994969829917, 0.03213956439867616, 0.031151605732738973, 0.030325006805360318, 0.029644135870039463, 0.029138021804392338, 0.028669308219105006, 0.028151529114693402, 0.027886245306581257, 0.02766454443335533, 0.02725004790350795, 0.027140396032482385, 0.026962172128260135];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_11.21.03 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'domain_news-novel  --0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-novel' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-05_16.34.26' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_11.21.03' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_12.03.51;domain_news-ency;boundary;96.21;94.96;95.58;word;93.34;92.13;92.73;20;1:25:48.839639;trainLosses  [0.17624464924109048, 0.08313833897589971, 0.06418471950309236, 0.05393587454487492, 0.047367476397219985, 0.04288351511031223, 0.03909668791726981, 0.03619775132759989, 0.03369619553731806, 0.03164513344621525, 0.029878442667882536, 0.028355576822211622, 0.026732795644946936, 0.025816096181268466, 0.024580221621101128, 0.02364859343428352, 0.022727484527621522, 0.022128997125022903, 0.02115846016241352, 0.020637773191712422];devLosses  [0.09500926882028579, 0.06779787257313728, 0.05582309499382973, 0.04926014471799135, 0.04485387694090605, 0.04182103663682937, 0.03942161858081818, 0.03767021400853991, 0.03609739150851965, 0.03500588603317738, 0.03400175135582686, 0.03303122749552131, 0.03248411225154996, 0.03192606685683131, 0.031435581259429454, 0.03116890661418438, 0.030758979748934507, 0.030445715468376874, 0.03014236567541957, 0.029752753246575593];--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_12.03.51 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'domain_news-ency  --0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-ency' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-06_02.23.41' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_12.03.51' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-06_14.13.21;domain_news-ency;boundary;97.04;92.0;94.45;word;94.78;89.86;92.25;5;0:09:18.336424;trainLosses  [0.13917934520784037, 0.05554871882140303, 0.04325746774631838, 0.03583785418691582, 0.030950706171173622];devLosses  [0.061873046644032, 0.04599392831325531, 0.04091932298615575, 0.040710354782640935, 0.03623558359220624];load from Nonedomain_news-ency , lr 0.0001, epoch 5;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_14.13.21 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from Nonedomain_news-ency  --lr 0.0001 --epoch 5' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-ency' --epoch 5 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_14.13.21' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_14.26.44;domain_novel-news;boundary;88.2;95.78;91.83;word;81.19;88.16;84.53;5;0:08:18.973910;trainLosses  [0.1481963268869636, 0.0645846121911727, 0.050275818135907605, 0.04216121127548155, 0.03662680345236431];devLosses  [0.07399977859238098, 0.054653524324811735, 0.04568792271545564, 0.0403801571235232, 0.03683580815706445];load from LM_2019-11-05_21.38.09domain_novel-news , lr 0.0001, epoch 5;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_14.26.44 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-05_21.38.09domain_novel-news  --lr 0.0001 --epoch 5' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 5 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-05_21.38.09' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_14.26.44' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-06_14.41.04;domain_novel-news;boundary;89.32;96.0;92.54;word;82.89;89.08;85.88;5;0:08:16.618096;trainLosses  [0.13365283134351275, 0.05595197722353228, 0.045891166849520486, 0.03966715124590163, 0.034990628633704314];devLosses  [0.06058898204188237, 0.04809341061560587, 0.04163469898717842, 0.03846867476729141, 0.033827282916540385];load from Nonedomain_novel-news , lr 0.0001, epoch 5;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_14.41.04 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from Nonedomain_novel-news  --lr 0.0001 --epoch 5' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 5 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_14.41.04' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_14.55.24;domain_novel-ency;boundary;90.77;96.18;93.4;word;84.26;89.28;86.7;5;0:08:19.779493;trainLosses  [0.16188395766532002, 0.07384941578098578, 0.059220021225549466, 0.05070806971877514, 0.04491512989859335];devLosses  [0.08338252643401596, 0.06340020017205984, 0.05384193711924827, 0.04797330965427147, 0.04382608711034402];load from LM_2019-11-06_02.23.41domain_novel-ency , lr 0.0001, epoch 5;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_14.55.24 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-06_02.23.41domain_novel-ency  --lr 0.0001 --epoch 5' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-ency' --epoch 5 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-06_02.23.41' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_14.55.24' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-06_15.07.48;domain_novel-ency;boundary;92.17;96.97;94.51;word;86.58;91.08;88.77;5;0:08:16.550376;trainLosses  [0.13326561515074428, 0.05574707604532865, 0.0458505548719298, 0.03963657149848477, 0.03499471816238971];devLosses  [0.05991295245529591, 0.04869029790848151, 0.04156812233315117, 0.03879996476930448, 0.03406535444417219];load from Nonedomain_novel-ency , lr 0.0001, epoch 5;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_15.07.48 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from Nonedomain_novel-ency  --lr 0.0001 --epoch 5' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-ency' --epoch 5 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_15.07.48' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_16.28.02;domain_novel-news;boundary;89.91;96.24;92.97;word;84.16;90.09;87.03;20;1:07:53.551415;trainLosses  [0.15676064709734977, 0.0668395365958088, 0.05223097565148643, 0.043875392828249, 0.03820994216012745, 0.03402510925135271, 0.030558481777377015, 0.02774939489733409, 0.025513671141997655, 0.023824229650433414, 0.022258797426469364, 0.02061688798554616, 0.01942213997361835, 0.018422229503323534, 0.017452844164694597, 0.016760120163648272, 0.016020312480600412, 0.015266853714614507, 0.014624967567398022, 0.014203255231510942];devLosses  [0.07650602429077544, 0.05679739480731131, 0.04745953470125966, 0.041894977612570786, 0.03814222659359033, 0.0355380860681849, 0.03359397053290373, 0.032176088113551854, 0.031008931476323085, 0.030234939172521406, 0.02970738580514645, 0.02922278828918934, 0.02884590073392309, 0.028560443963298852, 0.02817648426554669, 0.02804731325000182, 0.02793327858136303, 0.027723877123375047, 0.027722596458491237, 0.027709147475402932];load from LM_2019-11-05_21.38.09 , domain_novel-news , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_16.28.02 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-05_21.38.09  --domain_novel-news  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-05_21.38.09' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_16.28.02' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-06_18.50.38;domain_novel-news;boundary;91.63;95.43;93.49;word;86.72;90.32;88.48;10;0:16:38.044089;trainLosses  [0.13149173956963434, 0.05557779772628342, 0.04551813497334419, 0.039305547806878935, 0.03482710388512467, 0.031246426777361926, 0.028129035590600277, 0.02552948856548448, 0.023218673143779213, 0.021286350570796947];devLosses  [0.059961785615860734, 0.047652896193937325, 0.041663766142794455, 0.03898575657914425, 0.034182244911789894, 0.03181235014792831, 0.029936697762245418, 0.028354893813188047, 0.027678219301775955, 0.02787323079831984];load from None , domain_novel-news , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_18.50.38 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --domain_novel-news  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_18.50.38' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_19.13.29;domain_novel-ency;boundary;93.19;96.5;94.81;word;88.52;91.66;90.06;20;0:33:09.840806;trainLosses  [0.15724331217270401, 0.07371094316506206, 0.05895405772830074, 0.050526193347782945, 0.04465551477805454, 0.04040987571074286, 0.03687986059479378, 0.03400914827548904, 0.031516362449631616, 0.02966772010971104, 0.02790974869612773, 0.026353296959519986, 0.02501180567123445, 0.023624187473432354, 0.02260271641636389, 0.021657413349079727, 0.02059794709100458, 0.019827656052426326, 0.019080351311573058, 0.018487799619020303];devLosses  [0.08330183270676382, 0.06350371716865177, 0.0538937031537637, 0.04806913212798108, 0.04403143633028556, 0.04106782721462606, 0.03881053774264352, 0.03705657226429589, 0.03575686149127867, 0.034519910790968215, 0.03355511978011707, 0.03286781052834001, 0.0322602681986902, 0.03178301742621537, 0.031263294469179775, 0.030809857636347585, 0.030530178063045973, 0.030263349820656336, 0.030088257429928614, 0.02976074020496045];load from LM_2019-11-06_02.23.41 , domain_novel-ency , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_19.13.29 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-06_02.23.41  --domain_novel-ency  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-ency' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-06_02.23.41' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_19.13.29' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-06_19.50.47;domain_novel-ency;boundary;95.05;95.59;95.32;word;91.62;92.14;91.88;11;0:18:14.735652;trainLosses  [0.13199086950614525, 0.05541360622094055, 0.045533269384042854, 0.039385029767644616, 0.03498234861441443, 0.03137625988582196, 0.028269045770954546, 0.025859340087009883, 0.02358256952706069, 0.02158709740425324, 0.019902312063410803];devLosses  [0.059958755798723506, 0.048468542681343256, 0.04197719264989612, 0.0391743762696954, 0.03468411349445239, 0.032230664344354606, 0.029841214760966683, 0.028700734542190343, 0.028005060065409232, 0.027732229331272774, 0.028743755008126128];load from None , domain_novel-ency , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_19.50.47 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --domain_novel-ency  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-ency' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_19.50.47' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-06_22.57.03;domain_article-novel;boundary;96.69;95.33;96.0;word;94.13;92.8;93.46;8;0:25:51.647524;trainLosses  [0.06026220659725368, 0.02318609878110389, 0.01775110757133613, 0.014704231135547162, 0.012428027583907047, 0.01065771719518428, 0.009540683578234167, 0.00855123922500449];devLosses  [0.025848386535311445, 0.020567177205949146, 0.018661716665305635, 0.017337576787480536, 0.017125452498850578, 0.016991866752505302, 0.016883961993324405, 0.0170191049521022];load from LM_2019-10-31_07.39.25 , domain_article-novel , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-06_22.57.03 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-10-31_07.39.25  --domain_article-novel  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_article-novel' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-31_07.39.25' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-06_22.57.03' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-07_10.25.04;domain_article-novel;boundary;96.63;95.36;95.99;word;93.99;92.76;93.37;8;0:12:08.834331;trainLosses  [0.06061298777349293, 0.023586522978730498, 0.01806142755318433, 0.014703602419079592, 0.0125733027777945, 0.010779670694222053, 0.009662837644573301, 0.008655599501216783];devLosses  [0.026299665161572835, 0.02076566983562182, 0.018884966684067073, 0.01759828321690507, 0.017140948871041044, 0.016988933456185108, 0.01677051463219173, 0.017105771228671074];load from LM_2019-10-31_07.39.25 , domain_article-novel , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-07_10.25.04 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-10-31_07.39.25  --domain_article-novel  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_article-novel' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-31_07.39.25' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-07_10.25.04' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-07_13.55.25;domain_article-novel;boundary;96.93;94.49;95.7;word;94.57;92.19;93.36;6;0:08:58.069446;trainLosses  [0.058512573456391694, 0.022988089562083282, 0.01770880613010377, 0.014590593818575144, 0.012418864662759006, 0.010734715884706626];devLosses  [0.025410494904088622, 0.02035863119561006, 0.01841131434775889, 0.017408657271195862, 0.016871733851182985, 0.016986764981137478];load from LM_2019-10-31_07.39.25 , domain_article-novel , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-07_13.55.25 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-10-31_07.39.25  --domain_article-novel  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_article-novel' --epoch 20 --hidden_dim 514 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-31_07.39.25' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-07_13.55.25' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_12.54.56;test_100_line;boundary;44.01;16.65;24.17;word;37.28;14.11;20.47;1;0:00:04.200407;trainLosses  [0.9165843278169632];devLosses  [0.5477956508596739];load from None , test_100_line , lr 1, epoch 1;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --len_lines_per_chunk 100 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_12.54.56 --sequence_length 50 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --test_100_line  --lr 1 --epoch 1' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'test_100_line' --epoch 1 --hidden_dim 10 --layer_num 1 --learning_rate 1 --len_lines_per_chunk 100  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_12.54.56' --sequence_length 50 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_13.07.11;test_100_line;boundary;56.11;28.14;37.49;word;44.36;22.25;29.63;1;0:00:04.080519;trainLosses  [0.7312853634357452];devLosses  [0.5021355152130127];load from None , test_100_line , lr 1, epoch 1;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --len_lines_per_chunk 100 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_13.07.11 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --test_100_line  --lr 1 --epoch 1' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'test_100_line' --epoch 1 --hidden_dim 10 --layer_num 1 --learning_rate 1 --len_lines_per_chunk 100  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_13.07.11' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_13.16.29;test_100_line;boundary;28.53;64.37;39.54;word;5.71;12.88;7.91;1;0:00:04.016546;trainLosses  [1.4605514481663704];devLosses  [0.9147209723790487];load from None , test_100_line , lr 1, epoch 1;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --len_lines_per_chunk 100 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_13.16.29 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --test_100_line  --lr 1 --epoch 1' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'test_100_line' --epoch 1 --hidden_dim 10 --layer_num 1 --learning_rate 1 --len_lines_per_chunk 100  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_13.16.29' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-10_13.28.38;domain_news-article;boundary;98.24;97.46;97.85;word;96.8;96.03;96.42;5;0:22:23.482167;trainLosses  [0.058783332208154855, 0.02529524398518593, 0.019574750973593576, 0.01599607222617903, 0.013818006858075802];devLosses  [0.02946398364804169, 0.02260163208783263, 0.020598755430171985, 0.01925150328085269, 0.01950027732787156];load from LM_2019-11-09_05.29.48 , domain_news-article , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-10_13.28.38 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_05.29.48  --domain_news-article  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-article' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_05.29.48' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_13.28.38' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_17.25.05;test_100_line;boundary;40.47;25.77;31.49;word;27.95;17.79;21.74;1;0:00:04.110504;trainLosses  [0.9641228062765939];devLosses  [0.593071711063385];load from None , test_100_line , lr 1, epoch 1;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --len_lines_per_chunk 100 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_17.25.05 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --test_100_line  --lr 1 --epoch 1' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'test_100_line' --epoch 1 --hidden_dim 10 --layer_num 1 --learning_rate 1 --len_lines_per_chunk 100  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_17.25.05' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_17.28.50;test_100_line;boundary;82.81;5.57;10.44;word;82.46;5.55;10.39;1;0:00:04.060300;trainLosses  [1.216273648398263];devLosses  [0.7139295816421509];load from None , test_100_line , lr 1, epoch 1;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --len_lines_per_chunk 100 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_17.28.50 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --test_100_line  --lr 1 --epoch 1' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'test_100_line' --epoch 1 --hidden_dim 10 --layer_num 1 --learning_rate 1 --len_lines_per_chunk 100  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_17.28.50' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_17.31.52;test_100_line;boundary;22.6;30.27;25.88;word;7.84;10.5;8.98;1;0:00:04.066367;trainLosses  [1.2238538350377763];devLosses  [0.7959356546401978];load from None , test_100_line , lr 1, epoch 1;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --len_lines_per_chunk 100 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_17.31.52 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --test_100_line  --lr 1 --epoch 1' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'test_100_line' --epoch 1 --hidden_dim 10 --layer_num 1 --learning_rate 1 --len_lines_per_chunk 100  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_17.31.52' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_17.37.49;test_100_line;boundary;-;LM;Tokenizer_2019-11-10_17.46.15;domain_news-article;boundary;97.91;98.39;98.15;word;96.23;96.7;96.47;8;0:17:41.486618;trainLosses  [0.05969706720063806, 0.02534814918694716, 0.019225629054884005, 0.015619066259797724, 0.013210883601334508, 0.01167162002100708, 0.010383551222319043, 0.00925757899183218];devLosses  [0.029036642014980317, 0.02286566491238773, 0.020211989562958478, 0.01914108496159315, 0.019093478545546532, 0.01832027659751475, 0.01830046845600009, 0.018387468177825213];load from LM_2019-11-09_05.29.48 , domain_news-article , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-10_17.46.15 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_05.29.48  --domain_news-article  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-article' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_05.29.48' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_17.46.15' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_18.08.30;domain_news-article;boundary;86.77;89.94;88.32;word;77.34;80.17;78.73;20;0:02:42.929814;trainLosses  [0.5663801723185864, 0.404163100666174, 0.2981210275568776, 0.2529150556918629, 0.23068893721649766, 0.21644032417728915, 0.20603936822387758, 0.19799274857150775, 0.19179764409138503, 0.18640011300088308, 0.18190531937936164, 0.17822115438776975, 0.17509056993203456, 0.1723733594797177, 0.17005754224747918, 0.167897872993067, 0.1661406213178315, 0.16439100056054207, 0.16288080157181403, 0.16160998462631715];devLosses  [0.48037162408232686, 0.3373912997543812, 0.2663033600896597, 0.23688835367560387, 0.21922886393964292, 0.20730830028653144, 0.1982203806936741, 0.19099020145833492, 0.18496968269348144, 0.17979980535805226, 0.17550322197377682, 0.17188803814351558, 0.16886855594813824, 0.16626648291945456, 0.16403691738843917, 0.16202814869582652, 0.16025275133550168, 0.15862954922020436, 0.1572151032835245, 0.15596139326691627];load from None , domain_news-article , lr 0.0001, epoch 20;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_18.08.30 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --domain_news-article  --lr 0.0001 --epoch 20' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'domain_news-article' --epoch 20 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_18.08.30' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-10_18.15.38;domain_ency-article;boundary;96.99;98.39;97.68;word;94.64;96.0;95.32;8;0:11:53.452847;trainLosses  [0.06643481801156119, 0.02704872910030563, 0.020487522694235136, 0.016852207592769022, 0.014452787915314586, 0.012705848050922107, 0.011130381956678278, 0.010025144570627132];devLosses  [0.03065422549843788, 0.0238204092126001, 0.021037219176915558, 0.019899536375746582, 0.019562938659818785, 0.019152057949792255, 0.019101734174359026, 0.019231169188225813];load from LM_2019-11-09_05.29.48 , domain_ency-article , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-10_18.15.38 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_05.29.48  --domain_ency-article  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_ency-article' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_05.29.48' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_18.15.38' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_18.32.05;domain_ency-article;boundary;85.09;90.34;87.64;word;74.37;78.96;76.6;20;0:01:53.720010;trainLosses  [0.5300001548428601, 0.3923841629119646, 0.2986650077327054, 0.2501054350909122, 0.22363342140735215, 0.20797178758871487, 0.1977121195442422, 0.1900914944981596, 0.1842072865976584, 0.17931930026147264, 0.17538648178252925, 0.17184961019440598, 0.16883299034012947, 0.1660255094004921, 0.16353435366252816, 0.1612210287830163, 0.15907023453625024, 0.15706616789466885, 0.15514087909566937, 0.15358872270817278];devLosses  [0.4654087473575334, 0.33156533259198184, 0.2649458516809277, 0.2299078199872397, 0.20981761790755996, 0.19756897331628584, 0.18889966080511422, 0.18213591573381782, 0.17679780497586817, 0.17242674014173953, 0.1686662787333467, 0.16531629658731303, 0.16235724853393727, 0.15969115686147733, 0.15728127104895456, 0.15506696734661446, 0.1530383693096333, 0.1511578931844324, 0.14937904510731087, 0.1477516315933457];load from None , domain_ency-article , lr 0.0001, epoch 20;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_18.32.05 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --domain_ency-article  --lr 0.0001 --epoch 20' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'domain_ency-article' --epoch 20 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_18.32.05' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-10_18.55.26;domain_news-article;boundary;97.77;98.23;98.0;word;96.01;96.46;96.24;7;0:15:03.513932;trainLosses  [0.059367171951762124, 0.02527735936949706, 0.019197008113621333, 0.015423974723622785, 0.013195683920558272, 0.011550697764412985, 0.010200616717338563];devLosses  [0.028788703996688127, 0.02239140333607793, 0.02014018900692463, 0.018792682299390434, 0.0185251260176301, 0.017976224441081285, 0.018159215264022352];load from LM_2019-11-09_05.29.48 , domain_news-article , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-10_18.55.26 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_05.29.48  --domain_news-article  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-article' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_05.29.48' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_18.55.26' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_19.25.33;domain_news-article;boundary;86.31;89.68;87.96;word;76.74;79.73;78.2;20;0:02:42.559851;trainLosses  [0.5254537633011461, 0.3881301838592444, 0.28919846165779584, 0.2461669601125424, 0.22348927491703513, 0.20967833415589518, 0.20004965991780746, 0.19271498677117865, 0.18686653147529622, 0.1823077721219489, 0.1785611247799916, 0.17552554050470864, 0.1726832412308155, 0.17029505096500813, 0.16835355137646532, 0.16637271255587732, 0.16479511031225408, 0.1632160462647177, 0.16195808589957947, 0.1608743442669927];devLosses  [0.4599475471675396, 0.3226940834522247, 0.2586646887660027, 0.22814346984028816, 0.21065105445683002, 0.19921466179192066, 0.19085902705788613, 0.18431612864136696, 0.17915675438940526, 0.17501188598573209, 0.17159472703933715, 0.1687393443286419, 0.16625008739531041, 0.1640948686748743, 0.16222365282475948, 0.16055598646402358, 0.15904668986797332, 0.15770358815789223, 0.15647048965096474, 0.1554045232385397];load from None , domain_news-article , lr 0.0001, epoch 20;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_19.25.33 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from None  --domain_news-article  --lr 0.0001 --epoch 20' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'domain_news-article' --epoch 20 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000  --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_19.25.33' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;-;Tokenizer_2019-11-10_19.59.12;domain_ency-article;boundary;85.19;91.66;88.3;word;74.69;80.37;77.42;20;0:01:52.328390;trainLosses  [0.18454457622722775, 0.17866225749521403, 0.17380964220444556, 0.16987490290874568, 0.16659537408297492, 0.1634982830640642, 0.16095787468924208, 0.15852455293248122, 0.15659401415807014, 0.15480493517940183, 0.1531264297330195, 0.15153848753290247, 0.15038960931645046, 0.1489797625948767, 0.14786649638666985, 0.14687944661458527, 0.14568339177720802, 0.14462056085042285, 0.143910975715399, 0.14301168736443834];devLosses  [0.17633833461686185, 0.17094085875310397, 0.16647005092380637, 0.16273897583771468, 0.15951480699661083, 0.1567121242222033, 0.15421534525720695, 0.15203918695897983, 0.1500648632085413, 0.14832087622997456, 0.14676682763081744, 0.145304359663698, 0.14398937403483497, 0.142743845015092, 0.14157547768121376, 0.14048296605285845, 0.13944820051354573, 0.13853303740795395, 0.13761240115067117, 0.1367633080572114];load from Tokenizer_2019-11-10_19.59.12 , domain_ency-article , lr 0.0001, epoch 20;--batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 1 --optim adam --load_from Tokenizer_2019-11-10_19.59.12 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from Tokenizer_2019-11-10_19.59.12  --domain_ency-article  --lr 0.0001 --epoch 20' --batchSize 30 --char_dropout_prob 0.01 --char_embedding_size 10 --clip_grad 0.5 --dataset_size 'domain_ency-article' --epoch 20 --hidden_dim 10 --layer_num 1 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'Tokenizer_2019-11-10_19.59.12' --lr_decay 0.01 --lstm_num_direction 1 --optim 'adam' --over_write 1 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_19.59.12' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-10_20.29.50;domain_novel-article;boundary;95.39;98.51;96.92;word;92.05;95.06;93.53;6;2:33:07.042893;trainLosses  [0.05969876943193563, 0.027620437058933717, 0.021485910354294445, 0.017860785614577445, 0.015157637347808884, 0.013186982953359358];devLosses  [0.03166546040996053, 0.02518234586064843, 0.02315098228168556, 0.02238886334515851, 0.02194466065058763, 0.022476365168889362];load from LM_2019-11-09_05.29.48 , domain_novel-article , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-10_20.29.50 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_05.29.48  --domain_novel-article  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-article' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_05.29.48' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-10_20.29.50' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_00.01.02;domain_ency-article;boundary;97.13;98.11;97.62;word;94.95;95.9;95.43;9;0:14:07.101823;trainLosses  [0.06456072481127295, 0.02670259011657164, 0.020187373959792088, 0.0166159448233626, 0.014251916431540815, 0.012534249813993254, 0.011034134407732848, 0.010000149006871765, 0.009098496605592003];devLosses  [0.030118516646325588, 0.023343646207429243, 0.020887730022271473, 0.020142423497004944, 0.01947620889228402, 0.019284946307765716, 0.019237902692773125, 0.019160129369772745, 0.019215541701255875];load from LM_2019-11-09_05.29.48 , domain_ency-article , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_00.01.02 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_05.29.48  --domain_ency-article  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_ency-article' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_05.29.48' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_00.01.02' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
#---------------
-;LM;Tokenizer_2019-11-11_01.21.45;domain_article-news;boundary;95.48;96.77;96.12;word;92.68;93.92;93.29;6;0:08:43.251319;trainLosses  [0.06127683168277145, 0.023410612447187305, 0.01792974227418502, 0.014691195914832254, 0.012476079471719762, 0.010716662952521196];devLosses  [0.026109278667718172, 0.020646954242907026, 0.018669932710883373, 0.01732137904721586, 0.016802136060398293, 0.017050117966445053];load from LM_2019-11-09_20.22.33 , domain_article-news , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_01.21.45 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_20.22.33  --domain_article-news  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_article-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_20.22.33' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_01.21.45' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_01.53.14;domain_novel-news;boundary;90.86;97.79;94.2;word;85.59;92.12;88.74;6;0:11:32.279310;trainLosses  [0.058582998442477614, 0.027225800485691832, 0.021257354542098227, 0.017690802844774783, 0.015125736922386042, 0.013159281725705081];devLosses  [0.030835640306274097, 0.024797996313407504, 0.02259978310515483, 0.02166393674353416, 0.021226352605240785, 0.022449711905043017];load from LM_2019-11-09_20.22.33 , domain_novel-news , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_01.53.14 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_20.22.33  --domain_novel-news  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_20.22.33' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_01.53.14' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_02.27.03;domain_ency-news;boundary;93.83;96.42;95.11;word;89.96;92.44;91.19;7;0:10:25.261782;trainLosses  [0.06411867267277463, 0.026381861725381497, 0.019942151706173507, 0.016391487160111136, 0.01404885070924123, 0.012316859970674478, 0.010739519616336748];devLosses  [0.030038456206746174, 0.02326746592580369, 0.020774098564729546, 0.01975567504820047, 0.01952114783114556, 0.018877986225892197, 0.019153813669232255];load from LM_2019-11-09_20.22.33 , domain_ency-news , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_02.27.03 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-09_20.22.33  --domain_ency-news  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_ency-news' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-09_20.22.33' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_02.27.03' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_02.59.38;domain_article-ency;boundary;97.33;96.23;96.78;word;95.37;94.29;94.83;8;0:11:40.119143;trainLosses  [0.058778718253597616, 0.02345738446805626, 0.01796588040733089, 0.014828489862071971, 0.012547326592418055, 0.0107821026762637, 0.0097552880908673, 0.008807215578077981];devLosses  [0.02590733517290038, 0.02079351816107245, 0.018841372926116866, 0.017219662433490157, 0.016999447211513623, 0.01693569767453215, 0.016772040563142476, 0.017017547137049192];load from LM_2019-11-08_15.07.44 , domain_article-ency , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_02.59.38 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-08_15.07.44  --domain_article-ency  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_article-ency' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-08_15.07.44' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_02.59.38' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_03.26.43;domain_novel-ency;boundary;95.02;97.87;96.42;word;91.41;94.15;92.76;6;0:11:30.827243;trainLosses  [0.059647511852315475, 0.027530065700224596, 0.021610270530434707, 0.017953989173206102, 0.015426067800972443, 0.013457868161644019];devLosses  [0.031224292242664032, 0.024972511498236108, 0.02279906148283646, 0.021645690571388293, 0.021443523691389067, 0.021614156813285816];load from LM_2019-11-08_15.07.44 , domain_novel-ency , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_03.26.43 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-08_15.07.44  --domain_novel-ency  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_novel-ency' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-08_15.07.44' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_03.26.43' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_03.53.40;domain_news-ency;boundary;97.44;96.17;96.8;word;95.46;94.21;94.83;7;0:15:04.984742;trainLosses  [0.06010092920805822, 0.02572658343667258, 0.01953621400031131, 0.016043272096788585, 0.013661642736292251, 0.0120241604360372, 0.010799686336504848];devLosses  [0.029261331427842378, 0.023012385675683616, 0.020707851145416498, 0.01974372535943985, 0.01968515545129776, 0.01876282410696149, 0.01893863195553422];load from LM_2019-11-08_15.07.44 , domain_news-ency , lr 0.0001, epoch 20;--batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_03.53.40 --sequence_length 100 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-11-08_15.07.44  --domain_news-ency  --lr 0.0001 --epoch 20' --batchSize 60 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'domain_news-ency' --epoch 20 --hidden_dim 500 --layer_num 3 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-11-08_15.07.44' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_03.53.40' --sequence_length 100 --sgd_momentum 0.02 --with_dot 0
-;LM;Tokenizer_2019-11-11_04.24.19;best_full;boundary;98.5;98.72;98.61;word;97.32;97.54;97.43;13;7:02:52.303254;trainLosses  [0.08586042789318184, 0.037716667292326096, 0.029989893416791123, 0.025696575526369385, 0.022700542644574537, 0.020487995896635965, 0.018740565409436638, 0.017333791447148687, 0.016178300099373603, 0.015095994652751464, 0.0142455046540034, 0.013479661970459257, 0.012805565124917038];devLosses  [0.04142784149344288, 0.031870215093318506, 0.02772125051315151, 0.025471382348135632, 0.024158611434942752, 0.023189853316182223, 0.022445717112935006, 0.022101663419077943, 0.021806057616697613, 0.02151694857696099, 0.021436091521708528, 0.021275859849703548, 0.021299096968821922];load from LM_2019-10-19_17.05.50 , best_full , lr 0.0001, epoch 20;--batchSize 64 --char_dropout_prob 0.01 --char_embedding_size 200 --hidden_dim 514 --layer_num 2 --learning_rate 0.0001 --len_lines_per_chunk 1000 --lstm_num_direction 2 --optim adam --load_from Tokenizer_2019-11-11_04.24.19 --sequence_length 150 ;python Tokenizer.py --adam_lr_decay 0.0 --add_note 'load from LM_2019-10-19_17.05.50  --best_full  --lr 0.0001 --epoch 20' --batchSize 64 --char_dropout_prob 0.01 --char_embedding_size 200 --clip_grad 0.5 --dataset_size 'best_full' --epoch 20 --hidden_dim 514 --layer_num 2 --learning_rate 0.0001 --len_lines_per_chunk 1000 --load_from 'LM_2019-10-19_17.05.50' --lr_decay 0.01 --lstm_num_direction 2 --optim 'adam' --over_write 0 --printPrediction 0 --save_to 'Tokenizer_2019-11-11_04.24.19' --sequence_length 150 --sgd_momentum 0.02 --with_dot 0
